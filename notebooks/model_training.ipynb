{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Training for Product Classification\n",
    "\n",
    "This notebook handles the training of a Convolutional Neural Network (CNN) model for product image classification.\n",
    "\n",
    "## Objectives:\n",
    "- Prepare training data from scraped product images\n",
    "- Design and implement CNN architecture\n",
    "- Train the model with proper validation\n",
    "- Evaluate model performance\n",
    "- Save trained model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# Deep learning libraries\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "    TENSORFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"TensorFlow not available. Please install: pip install tensorflow\")\n",
    "    TENSORFLOW_AVAILABLE = False\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "from services.cnn_model import CNNModel\n",
    "from services.scraper import WebScraper\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'image_size': (224, 224),\n",
    "    'batch_size': 32,\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 0.001,\n",
    "    'validation_split': 0.2,\n",
    "    'test_split': 0.1,\n",
    "    'data_dir': '../data/scraped_images',\n",
    "    'model_save_path': '../models/cnn_product_classifier.h5',\n",
    "    'min_images_per_class': 10\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have scraped data, if not create sample data\n",
    "data_dir = Path(CONFIG['data_dir'])\n",
    "\n",
    "if not data_dir.exists() or len(list(data_dir.glob('*'))) == 0:\n",
    "    print(\"No scraped data found. Creating sample training data...\")\n",
    "    \n",
    "    # Create sample product categories and images\n",
    "    sample_products = [\n",
    "        'wireless_headphones',\n",
    "        'laptop_computer', \n",
    "        'smartphone',\n",
    "        'coffee_maker',\n",
    "        'running_shoes',\n",
    "        'backpack',\n",
    "        'watch',\n",
    "        'camera',\n",
    "        'tablet',\n",
    "        'speaker'\n",
    "    ]\n",
    "    \n",
    "    # Initialize web scraper\n",
    "    scraper = WebScraper(download_dir=str(data_dir))\n",
    "    \n",
    "    # Scrape images for each product\n",
    "    scraped_data = scraper.scrape_product_images(\n",
    "        sample_products, \n",
    "        images_per_product=CONFIG['min_images_per_class']\n",
    "    )\n",
    "    \n",
    "    # Create training dataset CSV\n",
    "    csv_path = scraper.create_training_dataset(scraped_data)\n",
    "    print(f\"Training dataset CSV created: {csv_path}\")\n",
    "    \n",
    "    # Get scraping statistics\n",
    "    stats = scraper.get_scraping_stats()\n",
    "    print(f\"Scraping statistics: {stats}\")\n",
    "else:\n",
    "    print(f\"Found existing data directory: {data_dir}\")\n",
    "\n",
    "# List available product categories\n",
    "if data_dir.exists():\n",
    "    categories = [d.name for d in data_dir.iterdir() if d.is_dir()]\n",
    "    print(f\"\\nAvailable product categories: {len(categories)}\")\n",
    "    for i, category in enumerate(categories, 1):\n",
    "        image_count = len(list((data_dir / category).glob('*')))\n",
    "        print(f\"  {i}. {category}: {image_count} images\")\n",
    "else:\n",
    "    print(\"No training data available. Please run the web scraper first.\")\n",
    "    categories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation and augmentation\n",
    "if TENSORFLOW_AVAILABLE and categories:\n",
    "    print(\"Preparing data generators...\")\n",
    "    \n",
    "    # Data augmentation for training\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.2,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=CONFIG['validation_split']\n",
    "    )\n",
    "    \n",
    "    # No augmentation for validation\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=CONFIG['validation_split']\n",
    "    )\n",
    "    \n",
    "    # Create data generators\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        str(data_dir),\n",
    "        target_size=CONFIG['image_size'],\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        str(data_dir),\n",
    "        target_size=CONFIG['image_size'],\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Get class information\n",
    "    num_classes = train_generator.num_classes\n",
    "    class_names = list(train_generator.class_indices.keys())\n",
    "    \n",
    "    print(f\"\\nDataset Information:\")\n",
    "    print(f\"  Number of classes: {num_classes}\")\n",
    "    print(f\"  Training samples: {train_generator.samples}\")\n",
    "    print(f\"  Validation samples: {validation_generator.samples}\")\n",
    "    print(f\"  Class names: {class_names}\")\n",
    "    \n",
    "    # Display class distribution\n",
    "    class_counts = {}\n",
    "    for class_name in class_names:\n",
    "        class_dir = data_dir / class_name\n",
    "        if class_dir.exists():\n",
    "            class_counts[class_name] = len(list(class_dir.glob('*')))\n",
    "    \n",
    "    print(\"\\nClass distribution:\")\n",
    "    for class_name, count in class_counts.items():\n",
    "        print(f\"  {class_name}: {count} images\")\n",
    "else:\n",
    "    print(\"Cannot prepare data - TensorFlow not available or no categories found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "if TENSORFLOW_AVAILABLE and categories:\n",
    "    print(\"Visualizing sample images...\")\n",
    "    \n",
    "    # Get a batch of training images\n",
    "    sample_batch = next(train_generator)\n",
    "    images, labels = sample_batch\n",
    "    \n",
    "    # Plot sample images\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(8, len(images))):\n",
    "        # Convert image back to displayable format\n",
    "        img = images[i]\n",
    "        \n",
    "        # Get class name\n",
    "        class_idx = np.argmax(labels[i])\n",
    "        class_name = class_names[class_idx]\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'Class: {class_name}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the plot\n",
    "    os.makedirs('../static/images', exist_ok=True)\n",
    "    plt.savefig('../static/images/sample_training_images.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Sample images saved to ../static/images/sample_training_images.png\")\n",
    "    \n",
    "    # Reset generator\n",
    "    train_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model\n",
    "if TENSORFLOW_AVAILABLE and categories:\n",
    "    print(\"Building CNN model...\")\n",
    "    \n",
    "    # Initialize CNN model service\n",
    "    cnn_service = CNNModel()\n",
    "    \n",
    "    # Create model architecture\n",
    "    model = cnn_service.create_model(\n",
    "        num_classes=num_classes,\n",
    "        input_shape=(*CONFIG['image_size'], 3)\n",
    "    )\n",
    "    \n",
    "    # Display model architecture\n",
    "    print(\"\\nModel Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Plot model architecture\n",
    "    try:\n",
    "        tf.keras.utils.plot_model(\n",
    "            model, \n",
    "            to_file='../static/images/model_architecture.png',\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "            rankdir='TB'\n",
    "        )\n",
    "        print(\"Model architecture diagram saved to ../static/images/model_architecture.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not save model diagram: {e}\")\n",
    "    \n",
    "    # Calculate total parameters\n",
    "    total_params = model.count_params()\n",
    "    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "    non_trainable_params = total_params - trainable_params\n",
    "    \n",
    "    print(f\"\\nModel Parameters:\")\n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_params:,}\")\n",
    "else:\n",
    "    print(\"Cannot build model - TensorFlow not available or no categories found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "if TENSORFLOW_AVAILABLE and categories and 'model' in locals():\n",
    "    print(\"Starting model training...\")\n",
    "    \n",
    "    # Define callbacks\n",
    "    callbacks_list = [\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=5,\n",
    "            min_lr=0.0001,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.ModelCheckpoint(\n",
    "            filepath=CONFIG['model_save_path'],\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Calculate steps per epoch\n",
    "    steps_per_epoch = train_generator.samples // CONFIG['batch_size']\n",
    "    validation_steps = validation_generator.samples // CONFIG['batch_size']\n",
    "    \n",
    "    print(f\"Training configuration:\")\n",
    "    print(f\"  Epochs: {CONFIG['epochs']}\")\n",
    "    print(f\"  Batch size: {CONFIG['batch_size']}\")\n",
    "    print(f\"  Steps per epoch: {steps_per_epoch}\")\n",
    "    print(f\"  Validation steps: {validation_steps}\")\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=CONFIG['epochs'],\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=callbacks_list,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining completed!\")\n",
    "    \n",
    "    # Save class names and metadata\n",
    "    metadata = {\n",
    "        'class_names': class_names,\n",
    "        'num_classes': num_classes,\n",
    "        'input_shape': [*CONFIG['image_size'], 3],\n",
    "        'training_config': CONFIG\n",
    "    }\n",
    "    \n",
    "    metadata_path = CONFIG['model_save_path'].replace('.h5', '_metadata.json')\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"Model metadata saved to {metadata_path}\")\n",
    "else:\n",
    "    print(\"Cannot train model - requirements not met\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "if 'history' in locals():\n",
    "    print(\"Visualizing training history...\")\n",
    "    \n",
    "    # Plot training history\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 0].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    axes[0, 0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    axes[0, 0].set_title('Model Accuracy')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 1].plot(history.history['loss'], label='Training Loss')\n",
    "    axes[0, 1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 1].set_title('Model Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Top-5 Accuracy (if available)\n",
    "    if 'top_5_accuracy' in history.history:\n",
    "        axes[1, 0].plot(history.history['top_5_accuracy'], label='Training Top-5 Accuracy')\n",
    "        axes[1, 0].plot(history.history['val_top_5_accuracy'], label='Validation Top-5 Accuracy')\n",
    "        axes[1, 0].set_title('Top-5 Accuracy')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Top-5 Accuracy')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True)\n",
    "    \n",
    "    # Learning rate (if available)\n",
    "    if 'lr' in history.history:\n",
    "        axes[1, 1].plot(history.history['lr'], label='Learning Rate')\n",
    "        axes[1, 1].set_title('Learning Rate Schedule')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Learning Rate')\n",
    "        axes[1, 1].set_yscale('log')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save training history plot\n",
    "    plt.savefig('../static/images/training_history.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Training history saved to ../static/images/training_history.png\")\n",
    "    \n",
    "    # Print final metrics\n",
    "    final_train_acc = history.history['accuracy'][-1]\n",
    "    final_val_acc = history.history['val_accuracy'][-1]\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "    final_val_loss = history.history['val_loss'][-1]\n",
    "    \n",
    "    print(f\"\\nFinal Training Metrics:\")\n",
    "    print(f\"  Training Accuracy: {final_train_acc:.4f}\")\n",
    "    print(f\"  Validation Accuracy: {final_val_acc:.4f}\")\n",
    "    print(f\"  Training Loss: {final_train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss: {final_val_loss:.4f}\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    overfitting_threshold = 0.1\n",
    "    acc_diff = final_train_acc - final_val_acc\n",
    "    if acc_diff > overfitting_threshold:\n",
    "        print(f\"\\n‚ö†Ô∏è  Warning: Possible overfitting detected (accuracy difference: {acc_diff:.4f})\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ Good generalization (accuracy difference: {acc_diff:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training summary report\n",
    "if 'history' in locals():\n",
    "    summary_report = f\"\"\"\n",
    "CNN MODEL TRAINING SUMMARY REPORT\n",
    "=================================\n",
    "\n",
    "Model Configuration:\n",
    "- Architecture: Custom CNN\n",
    "- Input Shape: {CONFIG['image_size']} x 3\n",
    "- Number of Classes: {num_classes}\n",
    "- Total Parameters: {total_params:,}\n",
    "- Trainable Parameters: {trainable_params:,}\n",
    "\n",
    "Training Configuration:\n",
    "- Epochs: {len(history.history['accuracy'])}\n",
    "- Batch Size: {CONFIG['batch_size']}\n",
    "- Learning Rate: {CONFIG['learning_rate']}\n",
    "- Validation Split: {CONFIG['validation_split']}\n",
    "\n",
    "Dataset Information:\n",
    "- Training Samples: {train_generator.samples}\n",
    "- Validation Samples: {validation_generator.samples}\n",
    "- Classes: {', '.join(class_names)}\n",
    "\n",
    "Final Performance:\n",
    "- Training Accuracy: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\n",
    "- Validation Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\n",
    "- Training Loss: {final_train_loss:.4f}\n",
    "- Validation Loss: {final_val_loss:.4f}\n",
    "\n",
    "Model Files:\n",
    "- Model: {CONFIG['model_save_path']}\n",
    "- Metadata: {metadata_path}\n",
    "- Training History: ../static/images/training_history.png\n",
    "- Sample Images: ../static/images/sample_training_images.png\n",
    "\n",
    "Next Steps:\n",
    "1. Test model on new images\n",
    "2. Integrate with Flask application\n",
    "3. Deploy for production use\n",
    "4. Monitor performance and retrain if needed\n",
    "\n",
    "Training completed successfully! üéâ\n",
    "\"\"\"\n",
    "    \n",
    "    print(summary_report)\n",
    "    \n",
    "    # Save report to file\n",
    "    with open('../data/training_report.txt', 'w') as f:\n",
    "        f.write(summary_report)\n",
    "    \n",
    "    print(\"\\nTraining report saved to ../data/training_report.txt\")\n",
    "else:\n",
    "    print(\"No training history available to generate report.\")"
   ]
  }
 ],
"metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
