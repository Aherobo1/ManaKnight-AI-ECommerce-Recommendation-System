{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-Commerce Dataset Cleaning\n",
    "\n",
    "This notebook handles the cleaning and preprocessing of the e-commerce dataset for the product recommendation system.\n",
    "\n",
    "## Objectives:\n",
    "- Load and explore the dataset\n",
    "- Remove duplicates and handle missing values\n",
    "- Standardize data formats\n",
    "- Prepare data for vectorization\n",
    "- Export cleaned data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path to import services\n",
    "sys.path.append('..')\n",
    "from services.database import DatabaseService\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from zip file\n",
    "data_path = '../data/dataset.zip'\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    with zipfile.ZipFile(data_path, 'r') as zip_ref:\n",
    "        # List files in zip\n",
    "        file_list = zip_ref.namelist()\n",
    "        print(\"Files in dataset.zip:\")\n",
    "        for file in file_list:\n",
    "            print(f\"  - {file}\")\n",
    "        \n",
    "        # Extract to temporary directory\n",
    "        zip_ref.extractall('../data/temp')\n",
    "        \n",
    "        # Find CSV files\n",
    "        csv_files = [f for f in file_list if f.endswith('.csv')]\n",
    "        if csv_files:\n",
    "            # Load the first CSV file\n",
    "            csv_file = csv_files[0]\n",
    "            df = pd.read_csv(f'../data/temp/{csv_file}')\n",
    "            print(f\"\\nLoaded dataset: {csv_file}\")\n",
    "            print(f\"Shape: {df.shape}\")\n",
    "        else:\n",
    "            print(\"No CSV files found in the zip archive\")\n",
    "            # Create sample data for demonstration\n",
    "            df = create_sample_data()\n",
    "else:\n",
    "    print(\"Dataset.zip not found. Creating sample data for demonstration.\")\n",
    "    df = create_sample_data()\n",
    "\n",
    "def create_sample_data():\n",
    "    \"\"\"Create sample e-commerce data for demonstration\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Sample product categories and descriptions\n",
    "    categories = ['Electronics', 'Clothing', 'Home & Garden', 'Sports', 'Books', 'Beauty']\n",
    "    electronics = ['Wireless Headphones', 'Smartphone', 'Laptop Computer', 'Tablet', 'Smart Watch', 'Bluetooth Speaker']\n",
    "    clothing = ['T-Shirt', 'Jeans', 'Dress', 'Jacket', 'Sneakers', 'Hat']\n",
    "    home_garden = ['Coffee Maker', 'Vacuum Cleaner', 'Plant Pot', 'Lamp', 'Cushion', 'Candle']\n",
    "    sports = ['Yoga Mat', 'Dumbbells', 'Running Shoes', 'Water Bottle', 'Fitness Tracker', 'Tennis Racket']\n",
    "    books = ['Programming Book', 'Novel', 'Cookbook', 'Biography', 'Science Book', 'Art Book']\n",
    "    beauty = ['Face Cream', 'Lipstick', 'Shampoo', 'Perfume', 'Nail Polish', 'Moisturizer']\n",
    "    \n",
    "    all_products = electronics + clothing + home_garden + sports + books + beauty\n",
    "    countries = ['USA', 'UK', 'Canada', 'Australia', 'Germany', 'France', 'Japan', 'China']\n",
    "    \n",
    "    # Generate sample data\n",
    "    n_samples = 1000\n",
    "    data = {\n",
    "        'StockCode': [f'SKU{i:04d}' for i in range(1, n_samples + 1)],\n",
    "        'Description': np.random.choice(all_products, n_samples),\n",
    "        'UnitPrice': np.random.uniform(5.0, 500.0, n_samples).round(2),\n",
    "        'Country': np.random.choice(countries, n_samples)\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset\n",
    "print(\"Dataset Exploration\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage': missing_percent\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nDuplicate records: {duplicates:,}\")\n",
    "\n",
    "# Data types\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Unique values in categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "print(\"\\nUnique values in categorical columns:\")\n",
    "for col in categorical_columns:\n",
    "    print(f\"{col}: {df[col].nunique():,} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning and preprocessing\n",
    "print(\"Data Cleaning Process\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "initial_rows = len(df_clean)\n",
    "\n",
    "# 1. Remove duplicates\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "print(f\"Removed {initial_rows - len(df_clean):,} duplicate rows\")\n",
    "\n",
    "# 2. Handle missing values\n",
    "# Remove rows with missing critical information\n",
    "critical_columns = ['StockCode', 'Description']\n",
    "for col in critical_columns:\n",
    "    if col in df_clean.columns:\n",
    "        before = len(df_clean)\n",
    "        df_clean = df_clean.dropna(subset=[col])\n",
    "        removed = before - len(df_clean)\n",
    "        if removed > 0:\n",
    "            print(f\"Removed {removed:,} rows with missing {col}\")\n",
    "\n",
    "# Fill missing values for non-critical columns\n",
    "if 'Country' in df_clean.columns:\n",
    "    df_clean['Country'] = df_clean['Country'].fillna('Unknown')\n",
    "\n",
    "if 'UnitPrice' in df_clean.columns:\n",
    "    # Remove rows with invalid prices\n",
    "    before = len(df_clean)\n",
    "    df_clean = df_clean[df_clean['UnitPrice'] > 0]\n",
    "    removed = before - len(df_clean)\n",
    "    if removed > 0:\n",
    "        print(f\"Removed {removed:,} rows with invalid prices\")\n",
    "\n",
    "# 3. Standardize text data\n",
    "if 'Description' in df_clean.columns:\n",
    "    # Clean description text\n",
    "    df_clean['Description'] = df_clean['Description'].astype(str)\n",
    "    df_clean['Description'] = df_clean['Description'].str.strip()\n",
    "    df_clean['Description'] = df_clean['Description'].str.title()\n",
    "    \n",
    "    # Remove very short descriptions\n",
    "    before = len(df_clean)\n",
    "    df_clean = df_clean[df_clean['Description'].str.len() >= 3]\n",
    "    removed = before - len(df_clean)\n",
    "    if removed > 0:\n",
    "        print(f\"Removed {removed:,} rows with very short descriptions\")\n",
    "\n",
    "# 4. Standardize stock codes\n",
    "if 'StockCode' in df_clean.columns:\n",
    "    df_clean['StockCode'] = df_clean['StockCode'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# 5. Standardize country names\n",
    "if 'Country' in df_clean.columns:\n",
    "    df_clean['Country'] = df_clean['Country'].str.strip().str.title()\n",
    "    \n",
    "    # Standardize common country name variations\n",
    "    country_mapping = {\n",
    "        'Usa': 'USA',\n",
    "        'United States': 'USA',\n",
    "        'Us': 'USA',\n",
    "        'Uk': 'UK',\n",
    "        'United Kingdom': 'UK',\n",
    "        'Britain': 'UK'\n",
    "    }\n",
    "    df_clean['Country'] = df_clean['Country'].replace(country_mapping)\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {df_clean.shape}\")\n",
    "print(f\"Removed {initial_rows - len(df_clean):,} rows in total ({((initial_rows - len(df_clean)) / initial_rows * 100):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality assessment\n",
    "print(\"Data Quality Assessment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for remaining issues\n",
    "print(\"Remaining missing values:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "print(\"\\nData type consistency:\")\n",
    "print(df_clean.dtypes)\n",
    "\n",
    "# Price distribution\n",
    "if 'UnitPrice' in df_clean.columns:\n",
    "    print(\"\\nPrice statistics:\")\n",
    "    print(df_clean['UnitPrice'].describe())\n",
    "    \n",
    "    # Check for outliers\n",
    "    Q1 = df_clean['UnitPrice'].quantile(0.25)\n",
    "    Q3 = df_clean['UnitPrice'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df_clean[(df_clean['UnitPrice'] < lower_bound) | (df_clean['UnitPrice'] > upper_bound)]\n",
    "    print(f\"Price outliers: {len(outliers):,} ({len(outliers)/len(df_clean)*100:.1f}%)\")\n",
    "\n",
    "# Top countries\n",
    "if 'Country' in df_clean.columns:\n",
    "    print(\"\\nTop 10 countries:\")\n",
    "    print(df_clean['Country'].value_counts().head(10))\n",
    "\n",
    "# Description length distribution\n",
    "if 'Description' in df_clean.columns:\n",
    "    df_clean['description_length'] = df_clean['Description'].str.len()\n",
    "    print(\"\\nDescription length statistics:\")\n",
    "    print(df_clean['description_length'].describe())\n",
    "    \n",
    "    # Most common words in descriptions\n",
    "    all_descriptions = ' '.join(df_clean['Description'].astype(str))\n",
    "    words = re.findall(r'\\b\\w+\\b', all_descriptions.lower())\n",
    "    word_freq = pd.Series(words).value_counts()\n",
    "    print(\"\\nTop 10 most common words in descriptions:\")\n",
    "    print(word_freq.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Price distribution\n",
    "if 'UnitPrice' in df_clean.columns:\n",
    "    axes[0, 0].hist(df_clean['UnitPrice'], bins=50, alpha=0.7, color='skyblue')\n",
    "    axes[0, 0].set_title('Price Distribution')\n",
    "    axes[0, 0].set_xlabel('Unit Price')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Country distribution\n",
    "if 'Country' in df_clean.columns:\n",
    "    top_countries = df_clean['Country'].value_counts().head(10)\n",
    "    axes[0, 1].bar(range(len(top_countries)), top_countries.values, color='lightcoral')\n",
    "    axes[0, 1].set_title('Top 10 Countries')\n",
    "    axes[0, 1].set_xlabel('Country')\n",
    "    axes[0, 1].set_ylabel('Number of Products')\n",
    "    axes[0, 1].set_xticks(range(len(top_countries)))\n",
    "    axes[0, 1].set_xticklabels(top_countries.index, rotation=45)\n",
    "\n",
    "# Description length distribution\n",
    "if 'description_length' in df_clean.columns:\n",
    "    axes[1, 0].hist(df_clean['description_length'], bins=30, alpha=0.7, color='lightgreen')\n",
    "    axes[1, 0].set_title('Description Length Distribution')\n",
    "    axes[1, 0].set_xlabel('Description Length (characters)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Price by country (top 5 countries)\n",
    "if 'UnitPrice' in df_clean.columns and 'Country' in df_clean.columns:\n",
    "    top_5_countries = df_clean['Country'].value_counts().head(5).index\n",
    "    price_by_country = [df_clean[df_clean['Country'] == country]['UnitPrice'].values for country in top_5_countries]\n",
    "    axes[1, 1].boxplot(price_by_country, labels=top_5_countries)\n",
    "    axes[1, 1].set_title('Price Distribution by Top 5 Countries')\n",
    "    axes[1, 1].set_xlabel('Country')\n",
    "    axes[1, 1].set_ylabel('Unit Price')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('../static/images/data_exploration.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Visualization saved to ../static/images/data_exploration.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data to database\n",
    "print(\"Saving cleaned data to database...\")\n",
    "\n",
    "try:\n",
    "    # Initialize database service\n",
    "    db_service = DatabaseService()\n",
    "    \n",
    "    # Save cleaned data to CSV first\n",
    "    cleaned_csv_path = '../data/cleaned_products.csv'\n",
    "    df_clean.to_csv(cleaned_csv_path, index=False)\n",
    "    print(f\"Cleaned data saved to {cleaned_csv_path}\")\n",
    "    \n",
    "    # Load data into database\n",
    "    products_loaded = db_service.load_products_from_csv(cleaned_csv_path)\n",
    "    print(f\"Successfully loaded {products_loaded:,} products into database\")\n",
    "    \n",
    "    # Verify data in database\n",
    "    sample_products = db_service.get_products(limit=5)\n",
    "    print(\"\\nSample products from database:\")\n",
    "    for product in sample_products:\n",
    "        print(f\"  {product['stock_code']}: {product['description']} - ${product['unit_price']:.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error saving to database: {e}\")\n",
    "    print(\"Data cleaning completed but not saved to database.\")\n",
    "\n",
    "print(\"\\nData cleaning process completed successfully!\")\n",
    "print(f\"Final dataset: {len(df_clean):,} products ready for vectorization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "summary_report = f\"\"\"\n",
    "E-COMMERCE DATASET CLEANING SUMMARY REPORT\n",
    "==========================================\n",
    "\n",
    "Dataset Information:\n",
    "- Original records: {initial_rows:,}\n",
    "- Final records: {len(df_clean):,}\n",
    "- Records removed: {initial_rows - len(df_clean):,} ({((initial_rows - len(df_clean)) / initial_rows * 100):.1f}%)\n",
    "- Columns: {len(df_clean.columns)}\n",
    "\n",
    "Data Quality:\n",
    "- Missing values: {df_clean.isnull().sum().sum()}\n",
    "- Duplicate records: 0 (removed)\n",
    "- Unique products: {df_clean['StockCode'].nunique() if 'StockCode' in df_clean.columns else 'N/A'}\n",
    "- Countries: {df_clean['Country'].nunique() if 'Country' in df_clean.columns else 'N/A'}\n",
    "\n",
    "Price Statistics:\n",
    "- Min price: ${df_clean['UnitPrice'].min():.2f if 'UnitPrice' in df_clean.columns else 'N/A'}\n",
    "- Max price: ${df_clean['UnitPrice'].max():.2f if 'UnitPrice' in df_clean.columns else 'N/A'}\n",
    "- Average price: ${df_clean['UnitPrice'].mean():.2f if 'UnitPrice' in df_clean.columns else 'N/A'}\n",
    "- Median price: ${df_clean['UnitPrice'].median():.2f if 'UnitPrice' in df_clean.columns else 'N/A'}\n",
    "\n",
    "Next Steps:\n",
    "1. Create product vectors for similarity search\n",
    "2. Set up vector database (Pinecone)\n",
    "3. Train recommendation model\n",
    "4. Implement API endpoints\n",
    "\n",
    "Files Generated:\n",
    "- ../data/cleaned_products.csv\n",
    "- ../static/images/data_exploration.png\n",
    "- Database populated with clean product data\n",
    "\"\"\"\n",
    "\n",
    "print(summary_report)\n",
    "\n",
    "# Save report to file\n",
    "with open('../data/cleaning_report.txt', 'w') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(\"\\nSummary report saved to ../data/cleaning_report.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
